#!/usr/bin/env python3
"""
Kiroç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è‡ªå‹•åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ 
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰å¿…è¦ãªè©³ç´°ãƒ«ãƒ¼ãƒ«ã‚’è‡ªå‹•åˆ¤å®šã—ã¦èª­ã¿è¾¼ã¿æŒ‡ç¤ºã‚’ç”Ÿæˆ
ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œç‰ˆ
"""

import re
import yaml
from pathlib import Path
from typing import List, Dict, Set, Tuple

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚ã®å¯¾å¿œï¼‰
try:
    from .session_cache import cached_read_file, get_session_cache
except ImportError:
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚ã‚„ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œæ™‚ã®å¯¾å¿œ
    def cached_read_file(file_path: str, explanation: str = "") -> str:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ãªã—ã®ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            return ""
    
    def get_session_cache():
        """ãƒ€ãƒŸãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        class DummyCache:
            def get_cache_stats(self):
                return {
                    'total_tokens_saved': 0,
                    'estimated_cost_savings': 0.0,
                    'hit_rate': 0.0
                }
        return DummyCache()

class KeywordDetector:
    def __init__(self, metadata_path: str = ".kiro/steering/rules-metadata.yml"):
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
        self.metadata_path = Path(metadata_path)
        self.rules_metadata = self._load_metadata()
        self.keyword_map = self._build_keyword_map()
    
    def _load_metadata(self) -> Dict:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(self.metadata_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            print(f"âš ï¸  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.metadata_path}")
            return {}
    
    def _build_keyword_map(self) -> Dict[str, List[str]]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’æ§‹ç¯‰ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ â†’ ãƒ«ãƒ¼ãƒ«åã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰"""
        keyword_map = {}
        
        for rule_name, rule_config in self.rules_metadata.get('rules', {}).items():
            if rule_config.get('auto_load', False):
                keywords = rule_config.get('keywords', [])
                for keyword in keywords:
                    if keyword not in keyword_map:
                        keyword_map[keyword] = []
                    keyword_map[keyword].append(rule_name)
        
        return keyword_map
    
    def detect_keywords(self, user_message: str) -> Tuple[Set[str], Dict[str, List[str]]]:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œçŸ¥
        
        Returns:
            Tuple[Set[str], Dict[str, List[str]]]: (æ¤œçŸ¥ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰, ãƒ«ãƒ¼ãƒ«åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹)
        """
        detected_keywords = set()
        rules_to_load = {}
        
        # å¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã—ãªã„æ¤œç´¢
        message_lower = user_message.lower()
        
        for keyword, rule_names in self.keyword_map.items():
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if keyword.lower() in message_lower:
                detected_keywords.add(keyword)
                
                for rule_name in rule_names:
                    rule_config = self.rules_metadata['rules'][rule_name]
                    file_path = rule_config.get('file_path')
                    
                    if file_path:
                        if rule_name not in rules_to_load:
                            rules_to_load[rule_name] = {
                                'file_path': file_path,
                                'description': rule_config.get('description', ''),
                                'priority': rule_config.get('priority', 'medium'),
                                'keywords': []
                            }
                        rules_to_load[rule_name]['keywords'].append(keyword)
        
        return detected_keywords, rules_to_load
    
    def generate_load_instructions(self, user_message: str) -> str:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«åŸºã¥ã„ã¦èª­ã¿è¾¼ã¿æŒ‡ç¤ºã‚’ç”Ÿæˆ
        
        Returns:
            str: Kiroå‘ã‘ã®èª­ã¿è¾¼ã¿æŒ‡ç¤ºï¼ˆMarkdownå½¢å¼ï¼‰
        """
        detected_keywords, rules_to_load = self.detect_keywords(user_message)
        
        if not detected_keywords:
            return "ğŸ“ åŸºæœ¬ãƒ«ãƒ¼ãƒ«ã®ã¿ã§å¯¾å¿œå¯èƒ½ã§ã™"
        
        # å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆ
        priority_order = {'critical': 0, 'high': 1, 'medium': 2, 'low': 3}
        sorted_rules = sorted(
            rules_to_load.items(),
            key=lambda x: priority_order.get(x[1]['priority'], 4)
        )
        
        instructions = []
        instructions.append("ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥ã«ã‚ˆã‚‹è©³ç´°ãƒ«ãƒ¼ãƒ«èª­ã¿è¾¼ã¿")
        instructions.append("")
        
        # æ¤œçŸ¥ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¡¨ç¤º
        keyword_list = "ã€".join(f'ã€Œ{kw}ã€' for kw in sorted(detected_keywords))
        instructions.append(f"**æ¤œçŸ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {keyword_list}")
        instructions.append("")
        
        # èª­ã¿è¾¼ã‚€ã¹ããƒ«ãƒ¼ãƒ«ã‚’è¡¨ç¤º
        instructions.append("**èª­ã¿è¾¼ã¿å¯¾è±¡**:")
        for rule_name, rule_info in sorted_rules:
            file_path = rule_info['file_path']
            description = rule_info['description']
            priority = rule_info['priority']
            keywords = "ã€".join(rule_info['keywords'])
            
            priority_emoji = {
                'critical': 'ğŸš¨',
                'high': 'âš¡',
                'medium': 'ğŸ“‹',
                'low': 'ğŸ“'
            }.get(priority, 'ğŸ“„')
            
            instructions.append(f"- {priority_emoji} **{rule_name}**: `{file_path}`")
            instructions.append(f"  - {description}")
            instructions.append(f"  - æ¤œçŸ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keywords}")
            instructions.append("")
        
        # Kiroå‘ã‘ã®å®Ÿè¡ŒæŒ‡ç¤ºï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰
        instructions.append("**Kiroå®Ÿè¡ŒæŒ‡ç¤º**:")
        instructions.append("```python")
        instructions.append("# ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ã—ãŸåŠ¹ç‡çš„ãªèª­ã¿è¾¼ã¿")
        instructions.append("from .session_cache import cached_read_file")
        instructions.append("")
        for rule_name, rule_info in sorted_rules:
            file_path = rule_info['file_path']
            instructions.append(f"cached_read_file('{file_path}', 'è©³ç´°ãƒ«ãƒ¼ãƒ«èª­ã¿è¾¼ã¿: {rule_name}')")
        instructions.append("```")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœã®è¡¨ç¤º
        cache = get_session_cache()
        stats = cache.get_cache_stats()
        if stats['total_tokens_saved'] > 0:
            instructions.append("")
            instructions.append("**ğŸ’° ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆç¯€ç´„åŠ¹æœ**:")
            instructions.append(f"- ç¯€ç´„ãƒˆãƒ¼ã‚¯ãƒ³: {stats['total_tokens_saved']:,}")
            instructions.append(f"- æ¨å®šç¯€ç´„é¡: ${stats['estimated_cost_savings']:.2f}")
            instructions.append(f"- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡: {stats['hit_rate']:.1f}%")
        
        return "\n".join(instructions)
    
    def get_implementation_rules(self) -> List[str]:
        """å®Ÿè£…é–‹å§‹æ™‚ã«å¿…è¦ãªå…¨ãƒ«ãƒ¼ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—"""
        implementation_rules = []
        
        for rule_name, rule_config in self.rules_metadata.get('rules', {}).items():
            if rule_config.get('auto_load', False):
                triggers = rule_config.get('triggers', [])
                if any(trigger in ['implementation-start', 'task-start', 'code-implementation'] 
                       for trigger in triggers):
                    file_path = rule_config.get('file_path')
                    if file_path:
                        implementation_rules.append(file_path)
        
        return implementation_rules

def main():
    """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    detector = KeywordDetector()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_messages = [
        "TASK-003ã‚’å®Ÿè£…ã—ã‚ˆã†",
        "ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã—ã¦ãƒªãƒªãƒ¼ã‚¹ã—ãŸã„", 
        "ãƒ†ã‚¹ãƒˆã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’ç¢ºèªã—ãŸã„",
        "ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆã—ã¦ã‚³ãƒŸãƒƒãƒˆã—ã‚ˆã†",
        "Specã®å“è³ªä¿è¨¼ã‚’ã—ãŸã„",
        "ç°¡å˜ãªè³ªå•ã§ã™"
    ]
    
    for message in test_messages:
        print(f"\n{'='*50}")
        print(f"ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {message}")
        print(f"{'='*50}")
        instructions = detector.generate_load_instructions(message)
        print(instructions)

if __name__ == "__main__":
    main()